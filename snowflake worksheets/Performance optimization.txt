-- Create a large warehouse with multiple clusters

CREATE WAREHOUSE COMPUTE_WH_PERFORMANCE
WITH WAREHOUSE_SIZE = 'LARGE'
WAREHOUSE_TYPE = 'STANDARD'
AUTO_SUSPEND = 60
AUTO_RESUME = TRUE
MIN_CLUSTER_COUNT = 1
MAX_CLUSTER_COUNT = 2
SCALING_POLICY = 'STANDARD';

-- Optimize data storage

-- Cluster the table by often used column to speed up queries

ALTER TABLE BIGDATA_PROJECT.PUBLIC.ECDC_GLOBAL_COPY CLUSTER BY (COUNTRY_REGION, CASES, DEATHS);

-- Create a new table with the same data ordered according to the clustering key

CREATE TABLE BIGDATA_PROJECT.PUBLIC.ECDC_GLOBAL_COPY_NEW CLUSTER BY (COUNTRY_REGION, CASES, DEATHS) AS SELECT * FROM BIGDATA_PROJECT.PUBLIC.ECDC_GLOBAL_COPY;

-- Test and comapre the data from both tables

SELECT * FROM BIGDATA_PROJECT.PUBLIC.ECDC_GLOBAL_COPY LIMIT 10;

SELECT * FROM BIGDATA_PROJECT.PUBLIC.ECDC_GLOBAL_COPY_NEW LIMIT 10;

-- Use Caching
-- Snowflake automatically caches query results, so if the same query will be ran again, it will return the result from the cache.
-- Running the same query multiple times will be faster after the first time.

-- Write efficient queries

-- Instead of this:

SELECT COUNTRY_REGION, SUM(CASES) AS TOTAL_CASES
FROM COVID19_EPIDEMIOLOGICAL_DATA.PUBLIC.ECDC_GLOBAL
WHERE COUNTRY_REGION = 'Latvia'
GROUP BY COUNTRY_REGION;

-- Write this:

WITH LATVIAN_DATA AS (
    SELECT *
    FROM COVID19_EPIDEMIOLOGICAL_DATA.PUBLIC.ECDC_GLOBAL
    WHERE COUNTRY_REGION = 'Latvia'
)
SELECT COUNTRY_REGION, SUM(CASES) AS TOTAL_CASES
FROM LATVIAN_DATA
GROUP BY COUNTRY_REGION;